{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9115fc0-3e24-4bd4-b019-110f70ef1ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install googletrans==4.0.0-rc1\n",
    "#!pip install langid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a95890-a43d-4e77-8ac2-dbe966d8ac8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from transformers import BertTokenizer,AutoTokenizer\n",
    "from transformers import BertModel,AutoModel\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from googletrans import Translator\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "import langid\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afb716d-3015-4a8a-b2c5-998f51137029",
   "metadata": {},
   "source": [
    "# Data Description\n",
    "For this competition, we curated a dataset comprised of around 4.5K book summaries labeled in seven genre categories: </br>Fiction (0), </br>Thriller (1), </br>Childrens-Book (2), </br>Political (3), </br>Science-Fiction (4), </br>War (5), and </br>Motivational (6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a458bf10-9636-45f7-a918-3fd8f9eb6fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0229bb4e-9afd-4b40-8ba6-6a8f97105a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d562b79a-d4ea-46e9-bb59-ba589a8c7ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test data\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71b611a-9cef-4b68-bc57-5f0f8500e78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looking for the missing data\n",
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f51acb-a083-4fc3-867c-579ce9804df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#before removing missing values \n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7c27ad-ab5a-44a0-a0d3-d9ef486aeb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove missing vlaues\n",
    "train.dropna(inplace=True)\n",
    "test.dropna(inplace=True)\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5dcbd3-1b2f-409a-bff1-857d859ccaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the distribution of data\n",
    "plt.hist(train['Label'],bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03860688-7508-4627-a23c-d91c90a210f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train['genre'],bins=20)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e54065c-8e53-43d3-acb4-d86df6d8cfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print a random train sample\n",
    "index = np.random.randint(0,len(train))\n",
    "print(f\"index : {index}\")\n",
    "train['summary'][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec618948-6f75-4756-8401-68aeccae3249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***************** Main Data Cleaning function***************************\n",
    "def clean_data(text):\n",
    "    text=text.replace('\\n',\"\")\n",
    "    text=text.replace('\\r',\"\")\n",
    "    text=re.sub(r'https?://\\S+|www\\.\\S+',' ',text)\n",
    "    cleaned_text = re.sub('[^a-zA-Z0-9\\u0980-\\u09FF,./!?$%&\"\\'\\\\-_;ред]',\" \",text) #remove unusual symbols such as emoji : # % @ * + etc \n",
    "    cleaned_text = re.sub('(?<=[\\s][^\\u0980-\\u09FFa-zA-Z0-9])[^\\u0980-\\u09FFA-Za-z0-9]+',\"\", cleaned_text) #remove multiples punctuations after space(doesnt remove the space)\n",
    "    cleaned_text = re.sub('(?<=[^\\u0980-\\u09FFa-zA-Z\\s0-9])[^\\u0980-\\u09FFA-Za-z0-9]',\" \", cleaned_text) #remove multiple punctuations just keeps the first one(no space before the punctuation)\n",
    "    cleaned_text = re.sub('\\s(?=[ред,.?!;])',\"\", cleaned_text) #remove the space before the punctuatuion mark\n",
    "    cleaned_text = ' '.join(cleaned_text.split()) #removes multiple spaces keeps only one \n",
    "    cleaned_text = re.sub(r'([ред,.?!;])(?=[\\u0980-\\u09E5a-zA-Z0-9\\u09F0-\\u09FF])',r'\\1 ', cleaned_text) #Make data standardized like there will e a space after a punctuation\n",
    "    cleaned_text = re.sub('(?<=[\\u0980-\\u09E5\\u09F0-\\u09FF])[.][\\s](?=[\\u0980-\\u09E5\\u09F0-\\u09FF])',' ', cleaned_text) #removes . from bangla text except from bangla digits\n",
    "   \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c9ee60-3490-4233-96e6-088fa11ff291",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the clean function\n",
    "index = np.random.randint(0,len(train))\n",
    "# index = 2933\n",
    "print(f\"Index : {index}\")\n",
    "clean_data(train['summary'][index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a0576c-151f-43e8-a074-17521d076ee4",
   "metadata": {},
   "source": [
    "# Create new features using cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7409fe-44e7-463f-9532-d583522bbfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "train['text']=train.summary.progress_apply(clean_data)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16b41be-1528-417c-83dd-2cd93dcc21be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating sentence length \n",
    "train['length'] = [len(x.split()) for x in train['text']]\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52066283-45a5-41e2-a76c-5dee62f0d0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping rows that got less datas\n",
    "train.drop(train[train['length'] < 50].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57de4448-c2c3-4012-8b68-bd5cc20652d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index(inplace=True)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb9141d-4570-46a0-8b26-21677f348134",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['Label']==2].summary.iloc[21]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9cb99b-247d-4b94-80cf-f579e388ccbe",
   "metadata": {},
   "source": [
    "# Translate the english too bangla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bb109b-0c6a-490e-b693-50d9bbeb77fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "\n",
    "def translate_to_bengali(text):\n",
    "    translator = Translator()\n",
    "    translation = translator.translate(text, src='en', dest='bn')\n",
    "    return translation.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76c9bec-fc8c-4638-8c20-6331890a59af",
   "metadata": {},
   "outputs": [],
   "source": [
    "holder=[]\n",
    "def ultimate_translator(text):\n",
    "    flag = re.search('[a-zA-Z0-9]+',text)\n",
    "    if flag is not None: #is there is english word in the text\n",
    "        flag1 = re.search('[\\u0980-\\u09FF]+',text)\n",
    "        if flag1 is None: # only english so direct translate\n",
    "            temp = translate_to_bengali(text)\n",
    "            holder.append(temp)\n",
    "            return temp\n",
    "        else: #mix of bangla and english\n",
    "            converted = \"\"\n",
    "            for words in text.split():\n",
    "                flag3 = re.search('[a-zA-Z0-9]',str(words))\n",
    "                if flag3 is not None: # the word is english so translate\n",
    "                    converted += translate_to_bengali(words)\n",
    "                    converted +=' '\n",
    "                else: # the word is bangla direct add\n",
    "                    converted += words\n",
    "                    converted +=' '\n",
    "            holder.append(converted)\n",
    "            return converted\n",
    "    else: #no english text  \n",
    "        holder.append(text)\n",
    "        return text    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc18ccab-7f31-49ff-a006-ddc07d5ed5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the translator function\n",
    "ultimate_translator(train['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d435f73e-0ff0-4e5f-ad12-3f0d01dc608c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "train['text'].progress_apply(ultimate_translator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734cb373-4b83-4368-8926-0cd32aadbc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_clean(text):\n",
    "    text=re.sub(\"'\",\"\",text)\n",
    "    pattern = r'[a-zA-Z0-9]'\n",
    "    \n",
    "    if re.match(pattern, text):\n",
    "        if re.search(r'[ржХ-рж╣]', text):\n",
    "            text = re.sub(pattern, \" \", text)\n",
    "        else:\n",
    "            text = translate_to_bengali(text)\n",
    "            text = re.sub(pattern, \" \", text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e875f6-7d4b-4f15-aed7-cd5880fc8e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "train['summary2']=train['text'].progress_apply(final_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da90796b-4ab1-4475-896a-71d342cf080a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating sentence length \n",
    "train['length'] = [len(x.split()) for x in train['text']]\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8465d2d3-478e-4c03-a497-77073cb33936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating rows with smaller length of sentence:\n",
    "smaller_train = len(train[train['length']<1])\n",
    "smaller_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff44c4c8-cba7-4aa0-bf1a-16a31c288e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['length']<1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f514f2cd-5238-4ee5-b676-34ad7cef0cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping rows that got less datas\n",
    "train.drop(train[train['length'] < 1].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880c77e6-9f99-4600-b005-dfd3161a5cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80402d3-8ed5-46a6-a435-dae69721401e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete all only english cell for now \n",
    "# Define a regex pattern for Bengali characters (Unicode range)\n",
    "bangla_pattern = re.compile(r'[\\u0980-\\u09FF]+')\n",
    "\n",
    "# Filter rows where 'text' column contains at least one Bengali character\n",
    "train = train[train['text'].apply(lambda x: bool(bangla_pattern.search(x)))]\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cadbca9-641d-4516-ab0f-ba86f30d6640",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now do same for the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b0c064-4a17-403b-a05b-4fc3d87df498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same for test\n",
    "tqdm.pandas()\n",
    "test['text']=test.summary.progress_apply(clean_data)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e599931-bf79-4de0-8114-91718cad3364",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['summary2']=test['text'].progress_apply(final_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3aa3f0-cf59-46a8-8f46-3de34af3634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['length'] = [len(x.split()) for x in test['text']]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9051e9-eaed-478c-9011-42dd101f4e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating rows with smaller length of sentence:\n",
    "smaller_test = len(test[test['length']<1])\n",
    "smaller_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaff1d13-adaa-44f5-8f8e-2ab5b2fdd127",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[test['length']<6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9df0cf0-ce74-4e31-9d0f-288697748b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test how to remove only english datas\n",
    "\n",
    "# Sample DataFrame (replace this with your actual DataFrame)\n",
    "data = {'text': ['ржЖржорж┐ ржмрж╛ржВрж▓рж╛ ржнрж╛рж╖рж╛ ржнрж╛рж▓ржмрж╛рж╕рж┐', 'I love Bengali ржЖрж╕ржжржл anguage', 'Some, English text', 'ржХрж┐ржЫрзБ ржмрж╛ржВрж▓рж╛ рж▓рзЗржЦрж╛']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define a regex pattern for Bengali characters (Unicode range)\n",
    "bangla_pattern = re.compile(r'[\\u0980-\\u09FF]+')\n",
    "\n",
    "# Filter rows where 'text' column contains at least one Bengali character\n",
    "df = df[df['text'].apply(lambda x: bool(bangla_pattern.search(x)))]\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dccf129-ec6e-4a5e-8170-574e07e5c7ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302ffae3-7d20-4234-9d82-33e6bfc41b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18eaf5a-bb25-47f7-980d-16ee931ed8f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7c2012-dded-4063-85ee-1aac7d405cac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bcde9e-cd9c-48dc-8b51-973777a7cb81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361c1588-29f4-4543-98fd-410df370755c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
